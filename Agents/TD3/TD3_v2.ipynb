{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TD3_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9WZo_B2_igzB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from functools import reduce\n",
        "import operator\n",
        "import random\n",
        "import traceback\n",
        "import abc\n",
        "import pickle\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import gym\n",
        "import gc\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atari shit"
      ],
      "metadata": {
        "id": "KN5plIbdpNQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive and indexing\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uSYU11qoVOD",
        "outputId": "bb5dab8f-1428-450d-a1e9-e48770818031"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir Atari"
      ],
      "metadata": {
        "id": "2LHges8PpTul"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rarfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLsaCVwepVVX",
        "outputId": "08512932-3ed6-44f5-830a-40da2cf5a810"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rarfile     \n",
        "file_path = \"/content/drive/MyDrive/DOT/Roms.rar\" \n",
        "extract_to_path = \"/content/Atari\"\n",
        "rf = rarfile.RarFile(file_path)\n",
        "rf.extractall(extract_to_path)"
      ],
      "metadata": {
        "id": "-9nXjbbDpX7M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m atari_py.import_roms /content/Atari"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfkK6pNlpa7J",
        "outputId": "4b0b2638-22f3-4481-b9cd-2bc25ca2d252"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copying assault.bin from /content/Atari/HC ROMS/NTSC VERSIONS OF PAL ORIGINALS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying king_kong.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/King Kong (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying mr_do.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/Mr. Do! (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying keystone_kapers.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/Keystone Kapers (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying laser_gates.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/Laser Gates (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying pacman.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/Pac-Man (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying koolaid.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Kool-Aid Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying montezuma_revenge.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Montezuma's Revenge - Featuring Panama Joe.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying jamesbond.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/James Bond 007.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying krull.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Krull.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying air_raid.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/A-G/Air Raid (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying adventure.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/A-G/Adventure (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying gravitar.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Gravitar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying crazy_climber.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Crazy Climber.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying elevator_action.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Elevator Action (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying alien.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Alien.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying sir_lancelot.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/S-Z/Sir Lancelot (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying star_gunner.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Stargunner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying up_n_down.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Up 'n Down.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying time_pilot.bin from /content/Atari/HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Time Pilot.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying lost_luggage.bin from /content/Atari/HC ROMS/BY COMPANY/Apollo - Games by Apollo/Lost Luggage [no opening scene].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying zaxxon.bin from /content/Atari/HC ROMS/BY COMPANY/Coleco/Zaxxon.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n",
            "copying donkey_kong.bin from /content/Atari/HC ROMS/BY COMPANY/Coleco/Donkey Kong.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying venture.bin from /content/Atari/HC ROMS/BY COMPANY/Coleco/Venture.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying carnival.bin from /content/Atari/HC ROMS/BY COMPANY/Coleco/Carnival.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying double_dunk.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Double Dunk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying kangaroo.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Kangaroo.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying breakout.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Breakout - Breakaway IV.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying video_pinball.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Video Pinball - Arcade Pinball.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying solaris.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Solaris.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying pong.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Video Olympics - Pong Sports.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying space_invaders.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Space Invaders.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying defender.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Defender.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying berzerk.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Berzerk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying asteroids.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Asteroids [no copyright].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying yars_revenge.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Yars' Revenge.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying centipede.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Centipede.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying surround.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Surround - Chase.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying phoenix.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Phoenix.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying galaxian.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Galaxian.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying road_runner.bin from patched version of /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Road Runner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying bowling.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Bowling.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying ms_pacman.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Ms. Pac-Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying battle_zone.bin from /content/Atari/HC ROMS/BY COMPANY/Atari - Sears/Battlezone.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying skiing.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Skiing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying chopper_command.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Chopper Command.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying pitfall.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Pitfall! - Pitfall Harry's Jungle Adventure.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying kung_fu_master.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Kung-Fu Master.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying private_eye.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Private Eye.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying frostbite.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Frostbite.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying seaquest.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Seaquest.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying enduro.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Enduro.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying riverraid.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/River Raid.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying boxing.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Boxing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying kaboom.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Kaboom!.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying ice_hockey.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Ice Hockey.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying fishing_derby.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Fishing Derby.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying beam_rider.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Beamrider.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying tennis.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Tennis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying hero.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/H.E.R.O..bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying freeway.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Freeway.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying robotank.bin from /content/Atari/HC ROMS/BY COMPANY/Activision/Robot Tank.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying trondead.bin from /content/Atari/HC ROMS/BY COMPANY/M Network - Mattel Electronics/TRON - Deadly Discs.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying wizard_of_wor.bin from /content/Atari/HC ROMS/BY COMPANY/CBS Electronics/Wizard of Wor.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying pooyan.bin from /content/Atari/HC ROMS/BY COMPANY/Konami/Pooyan.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying bank_heist.bin from /content/Atari/HC ROMS/BY COMPANY/20th Century Fox Video Games/Bank Heist.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying atlantis.bin from /content/Atari/HC ROMS/BY COMPANY/Imagic/Atlantis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying demon_attack.bin from /content/Atari/HC ROMS/BY COMPANY/Imagic/Demon Attack.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying tutankham.bin from /content/Atari/HC ROMS/BY COMPANY/Parker Brothers/Tutankham.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying qbert.bin from /content/Atari/HC ROMS/BY COMPANY/Parker Brothers/Q-bert.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying amidar.bin from /content/Atari/HC ROMS/BY COMPANY/Parker Brothers/Amidar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying frogger.bin from /content/Atari/HC ROMS/BY COMPANY/Parker Brothers/Frogger.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying journey_escape.bin from /content/Atari/HC ROMS/BY COMPANY/Data Age/Journey Escape.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying name_this_game.bin from /content/Atari/HC ROMS/BY COMPANY/U.S. Games Corporation/Name This Game.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying gopher.bin from /content/Atari/HC ROMS/BY COMPANY/U.S. Games Corporation/Gopher.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying asterix.bin from /content/Atari/ROMS/Asterix (AKA Taz) (1984) (Atari, Jerome Domurat, Steve Woita) (CX2696).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "p1qR3-3KpQBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentTree():\n",
        "    def __init__(self, capacity, operation, neutral_element):\n",
        "        assert capacity > 0 and capacity & (capacity - 1) == 0, 'capacity must me a positive power of 2'\n",
        "        self.capacity = capacity\n",
        "        self.operation = operation\n",
        "        self.neutral_element = neutral_element\n",
        "        self.memory = np.full(2 * self.capacity, self.neutral_element)\n",
        "    \n",
        "    def _reduce_helper(self, start, end, node, node_start, node_end):\n",
        "        if start == node_start and end == node_end:\n",
        "            return self.memory[node]\n",
        "        mid = (node_start + node_end) // 2\n",
        "        if end <= mid:\n",
        "            return self._reduce_helper(start, end, 2 * node, node_start, mid)\n",
        "        else:\n",
        "            if mid + 1 <= start:\n",
        "                return self._reduce_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
        "            else:\n",
        "                return self._operation(\n",
        "                    self._reduce_helper(start, mid, 2 * node, node_start, mid),\n",
        "                    self._reduce_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end)\n",
        "                )\n",
        "    \n",
        "    def reduce(self, start=0, end=0):\n",
        "        if end < 0:\n",
        "            end += self.capacity - 1\n",
        "        return self._reduce_helper(start, end, 1, 0, self.capacity - 1)\n",
        "    \n",
        "    def __setitem__(self, idx, val):\n",
        "        idx += self.capacity\n",
        "        self.memory[idx] = val\n",
        "\n",
        "        idx //= 2\n",
        "        while idx >= 1:\n",
        "            self.memory[idx] = self.operation(self.memory[2 * idx], self.memory[2 * idx + 1])\n",
        "            idx //= 2\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert 0 <= idx < self.capacity\n",
        "        return self.memory[self.capacity + idx]\n",
        "\n",
        "class SumSegmentTree(SegmentTree):\n",
        "    def __init__(self, capacity):\n",
        "        super(SumSegmentTree, self).__init__(\n",
        "            capacity=capacity, operation=operator.add, neutral_element=0.0)\n",
        "\n",
        "    def sum(self, start=0, end=0):\n",
        "        return super(SumSegmentTree, self).reduce(start, end)\n",
        "\n",
        "    def retrieve(self, upperbound):\n",
        "        idx = 1\n",
        "\n",
        "        while idx < self.capacity:\n",
        "            left = 2 * idx\n",
        "            right = left + 1\n",
        "            if self.memory[left] > upperbound:\n",
        "                idx = 2 * idx\n",
        "            else:\n",
        "                upperbound -= self.memory[left]\n",
        "                idx = right\n",
        "        return idx - self.capacity\n",
        "\n",
        "\n",
        "class MinSegmentTree(SegmentTree):\n",
        "    def __init__(self, capacity):\n",
        "        super(MinSegmentTree, self).__init__(\n",
        "            capacity=capacity, operation=min, neutral_element=float(\"inf\"))\n",
        "\n",
        "    def min(self, start=0, end=0):\n",
        "        return super(MinSegmentTree, self).reduce(start, end)"
      ],
      "metadata": {
        "id": "7hGTU10ux-Sk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrioritizedReplayBuffer():\n",
        "    def __init__(self, size, shape, actions, alpha):\n",
        "        assert size > 0 and size & (size - 1) == 0, 'size must me a positive power of 2'\n",
        "        self.size = size\n",
        "\n",
        "        assert shape is not None, 'shape must not be None'\n",
        "        self.shape = shape\n",
        "\n",
        "        #assert actions > 0, 'actions must me greater than 0'\n",
        "        self.actions = actions\n",
        "\n",
        "        assert 0 <= alpha <= 1, 'alpha must me between 0 and 1 (0: no prioritization, 1: full prioritization)'\n",
        "        self.alpha = alpha\n",
        "        self.max_priority = 1.0\n",
        "        self.tree_sum = SumSegmentTree(self.size)\n",
        "        self.tree_min = MinSegmentTree(self.size)\n",
        "\n",
        "        self.memory_initial_state = np.zeros((self.size, *self.shape))\n",
        "        #self.memory_action = np.zeros((self.size, *self.actions))\n",
        "        self.memory_action = [[] for _ in range(self.size)]\n",
        "        self.memory_reward = np.zeros(self.size)\n",
        "        self.memory_final_state = np.zeros((self.size, *self.shape))\n",
        "        self.memory_terminal = np.zeros(self.size, dtype=bool)\n",
        "\n",
        "        self.counter = 0\n",
        "  \n",
        "    def push(self, initial_state, action, reward, final_state, terminal):\n",
        "        index = self.counter % self.size\n",
        "\n",
        "        self.memory_initial_state[index] = initial_state\n",
        "        self.memory_action[index] = action\n",
        "        self.memory_reward[index] = reward\n",
        "        self.memory_final_state[index] = final_state\n",
        "        self.memory_terminal[index] = terminal\n",
        "\n",
        "        self.counter += 1\n",
        "\n",
        "        self.tree_sum[index] = self.max_priority ** self.alpha\n",
        "        self.tree_min[index] = self.max_priority ** self.alpha\n",
        "  \n",
        "    def pop(self, batch_size, beta):\n",
        "        assert 0 <= beta <= 1, 'beta must me between 0 and 1 (0: no correction, 1: full correction)'\n",
        "        indexes = self._sample_proportional(batch_size)\n",
        "        weights = []\n",
        "        sum_value = self.tree_sum.sum()\n",
        "        min_value = self.tree_min.min()\n",
        "        min_prob =  min_value / sum_value\n",
        "        max_weight = (min_prob * self.size) ** (- beta)\n",
        "        sample_prob = [self.tree_sum[i] / sum_value for i in indexes]\n",
        "        weights =  tf.convert_to_tensor([(p * self.size) ** (- beta) / max_weight for p in sample_prob], dtype=tf.float32)\n",
        "        indexes = tf.convert_to_tensor(indexes, dtype=tf.int32)\n",
        "\n",
        "        initial_states = tf.convert_to_tensor(self.memory_initial_state[indexes], dtype=tf.float32)\n",
        "        actions = [[tf.convert_to_tensor(action, dtype=tf.float32) for action in self.memory_action[index]] for index in indexes.numpy()]\n",
        "        actions = tf.squeeze(tf.convert_to_tensor(actions), axis=1)\n",
        "        rewards = tf.convert_to_tensor(self.memory_reward[indexes], dtype=tf.float32)\n",
        "        final_states = tf.convert_to_tensor(self.memory_final_state[indexes], dtype=tf.float32)\n",
        "        terminals = self.memory_terminal[indexes]\n",
        "\n",
        "        return initial_states, actions, rewards, final_states, terminals, weights, indexes\n",
        "  \n",
        "    def _sample_proportional(self, batch_size):\n",
        "        total = self.tree_sum.sum(0, self.size - 1)\n",
        "        mass = np.random.random(size=batch_size) * total\n",
        "        indexes = [self.tree_sum.retrieve(elem) for elem in mass]\n",
        "        return indexes\n",
        "  \n",
        "    def update_priorities(self, indexes, priorities):\n",
        "        assert len(indexes) == len(priorities)\n",
        "        assert np.min(priorities) > 0\n",
        "        assert np.min(indexes) >= 0\n",
        "        assert np.max(indexes) < self.size\n",
        "        for i in range(len(indexes)):\n",
        "            self.tree_sum[indexes[i]] = priorities[i] ** self.alpha\n",
        "            self.tree_min[indexes[i]] = priorities[i] ** self.alpha\n",
        "\n",
        "        self.max_priority = max(self.max_priority, np.max(priorities))"
      ],
      "metadata": {
        "id": "YbzwNWv_muHv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CriticNetwork(keras.Model):\n",
        "    def __init__(self, layer_list, model_name, checkpoint_dir='tmp/td3'):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "        self.model_name = model_name\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.checkpoint_file = os.path.join(self.checkpoint_dir, self.model_name + '_td3')\n",
        "        self.layer_list = layer_list\n",
        "    \n",
        "    def call(self, state, action):\n",
        "        #fix for images\n",
        "        action = tf.expand_dims(tf.expand_dims(action, axis=1), axis=1)\n",
        "        action = tf.repeat(tf.repeat(action, state.shape[1], axis=1), state.shape[2], axis=2)\n",
        "        return reduce(lambda input_data, l: l(input_data), self.layer_list, tf.concat([state, action], axis=3))\n",
        "\n",
        "\n",
        "class ActorNetwork(keras.Model):\n",
        "    def __init__(self, layer_list, model_name, checkpoint_dir='temp/td3'):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.model_name = model_name\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.checkpoint_file = os.path.join(self.checkpoint_dir, self.model_name + '_td3')\n",
        "        self.layer_list = layer_list\n",
        "    \n",
        "    def call(self, state):\n",
        "        return reduce(lambda input_data, l: l(input_data), self.layer_list, state)"
      ],
      "metadata": {
        "id": "_S6Usbm9xgM1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetworkBuilder:\n",
        "    def __init__(self):\n",
        "        self.supported_layers = {'Input': keras.layers.Input,\n",
        "                                 'Dense': keras.layers.Dense, \n",
        "                                 'Conv2D': keras.layers.Conv2D, \n",
        "                                 'Activation': keras.layers.Activation,\n",
        "                                 'BatchNormalization': keras.layers.BatchNormalization, \n",
        "                                 'Dropout': keras.layers.Dropout,\n",
        "                                 'Flatten': keras.layers.Flatten,\n",
        "                                 'Concatenate': keras.layers.Concatenate,\n",
        "                                 'GlobalAveragePooling2D': keras.layers.GlobalAveragePooling2D,\n",
        "                                 'GlobalMaxPooling2D': keras.layers.GlobalMaxPooling2D}\n",
        "\n",
        "    def build_network(self, params_dict):\n",
        "        return [self.build_layer(layer_dict) for layer_dict in params_dict.values()]\n",
        "      \n",
        "    def build_layer(self, layer_dict):\n",
        "        try:\n",
        "            return self.supported_layers[layer_dict['name']](**layer_dict['params'])\n",
        "        except KeyError:\n",
        "            print(traceback.format_exc())\n",
        "            print(\"Use one of the supported layers {}\".format(list(self.supported_layers.keys())))\n",
        "        except TypeError:\n",
        "            print(traceback.format_exc())\n",
        "            print(\"Use valid parameters\")"
      ],
      "metadata": {
        "id": "fhoVI2f33Rea"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, environment, batch_size, checkpoint_dir='tmp/agent_name', seed=42):\n",
        "        self.environment = environment \n",
        "        self.state_space_shape = self.environment.observation_space.shape\n",
        "        if type(self.environment.action_space) == gym.spaces.Discrete:\n",
        "            self.action_space_shape = (self.environment.action_space.n,)\n",
        "            self.action_number = 1\n",
        "        else:\n",
        "            self.action_space_shape = self.environment.action_space.nvec\n",
        "            self.action_number = self.environment.action_space.shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.learn_step_counter = 0\n",
        "        self.time_step = 0\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.seed = seed\n",
        "    \n",
        "    def act(self, observation):\n",
        "        raise NotImplementedError(\"act method needs to be implemented by subclasses\")\n",
        "    \n",
        "    def store(self, initial_state, action, reward, final_state, terminal):\n",
        "        raise NotImplementedError(\"store method needs to be implemented by subclasses\")\n",
        "    \n",
        "    def learn(self):\n",
        "        raise NotImplementedError(\"learn method needs to be implemented by subclasses\")\n",
        "    \n",
        "    def save(self):\n",
        "        raise NotImplementedError(\"save method needs to be implemented by subclasses\")\n",
        "    \n",
        "    def load(self):\n",
        "        raise NotImplementedError(\"load method needs to be implemented by subclasses\")"
      ],
      "metadata": {
        "id": "aKuig6FtGgcK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TD3Agent(Agent):\n",
        "    def __init__(self, environment, learning_rate_actor, learning_rate_critic,\n",
        "                 loss_actor, loss_critic, update_coeff_target, discount_factor, \n",
        "                 delay_coeff_actor, noise, warmup, memory_size, memory_alpha, \n",
        "                 memory_beta, batch_size, network_dict_actor, network_dict_critic,\n",
        "                 checkpoint_dir='tmp/td3', seed=42):\n",
        "        super(TD3Agent, self).__init__(environment, batch_size, checkpoint_dir, seed)\n",
        "        self.learning_rate_actor = learning_rate_actor\n",
        "        self.learning_rate_critic = learning_rate_critic\n",
        "        self.loss_actor = loss_actor\n",
        "        self.loss_critic = loss_critic\n",
        "        self.update_coeff_target = update_coeff_target\n",
        "        self.discount_factor = discount_factor\n",
        "        self.delay_coeff_actor = delay_coeff_actor\n",
        "        self.noise = noise\n",
        "        self.warmup = warmup\n",
        "        self.memory_size = memory_size\n",
        "        self.memory_alpha = memory_alpha\n",
        "        self.memory_beta = memory_beta\n",
        "        self.network_dict_actor = network_dict_actor\n",
        "        self.network_dict_critic = network_dict_critic\n",
        "\n",
        "        self.memory = PrioritizedReplayBuffer(self.memory_size, self.state_space_shape, \n",
        "                                              self.action_space_shape, self.memory_alpha)\n",
        "        \n",
        "        self.network_builder = NetworkBuilder()\n",
        "        self.actor = self._init_network(self.network_dict_actor, 'actor', self.checkpoint_dir,\n",
        "                                       Adam, self.learning_rate_actor, self.loss_actor, True)\n",
        "        self.critic_1 = self._init_network(self.network_dict_critic, 'critic_1', self.checkpoint_dir,\n",
        "                                       Adam, self.learning_rate_critic, self.loss_critic, False)\n",
        "        self.critic_2 = self._init_network(self.network_dict_critic, 'critic_2', self.checkpoint_dir,\n",
        "                                       Adam, self.learning_rate_critic, self.loss_critic, False)\n",
        "        self.target_actor = self._init_network(self.network_dict_actor, 'target_actor', self.checkpoint_dir,\n",
        "                                       Adam, self.learning_rate_actor, self.loss_actor, True)\n",
        "        self.target_critic_1 = self._init_network(self.network_dict_critic, 'target_critic_1', self.checkpoint_dir,\n",
        "                                       Adam, self.learning_rate_critic, self.loss_critic, False)\n",
        "        self.target_critic_2 = self._init_network(self.network_dict_critic, 'target_critic_2', self.checkpoint_dir,\n",
        "                                       Adam, self.learning_rate_critic, self.loss_critic, False)\n",
        "        \n",
        "        self.update_target(1)\n",
        "\n",
        "    def _init_network(self, params_dict, name, checkpoint_dir, optimizer, learning_rate, loss, actor=True):\n",
        "        if actor:\n",
        "            network = ActorNetwork(self.network_builder.build_network(params_dict), name, checkpoint_dir)\n",
        "        else:\n",
        "            network = CriticNetwork(self.network_builder.build_network(params_dict), name, checkpoint_dir)\n",
        "        network.compile(optimizer=optimizer(learning_rate=learning_rate), loss=loss)\n",
        "        return network\n",
        "    \n",
        "    def update_target_network(self, network, target_network, update_coeff_target):\n",
        "        weights = [w * update_coeff_target + target_network.weights[i] * (1 - update_coeff_target) for i, w in enumerate(network.weights)]\n",
        "        network.set_weights(weights)\n",
        "\n",
        "    def update_target(self, update_coeff_target=None):\n",
        "        if update_coeff_target is None:\n",
        "            update_coeff_target = self.update_coeff_target\n",
        "        \n",
        "        self.update_target_network(self.actor, self.target_actor, update_coeff_target)\n",
        "        self.update_target_network(self.critic_1, self.target_critic_1, update_coeff_target)\n",
        "        self.update_target_network(self.critic_2, self.target_critic_2, update_coeff_target)\n",
        "\n",
        "    def act(self, observation):\n",
        "        if self.time_step < self.warmup:\n",
        "            \"\"\"\n",
        "            if self.action_number == 1:\n",
        "                action_prob = np.random.dirichlet(np.ones(self.action_space_shape), size=1)[0]\n",
        "            else:\n",
        "                action_prob = [np.random.dirichlet(np.ones(self.action_space_shape[i]), size=1)[0] for i in range(self.action_number)]\n",
        "            \"\"\"\n",
        "            action_prob = [np.random.dirichlet(np.ones(self.action_space_shape[i]), size=1)[0] for i in range(self.action_number)]\n",
        "        else:\n",
        "            state = tf.convert_to_tensor([observation], dtype=tf.float32)\n",
        "            action_prob = self.actor(state) + np.random.normal(scale=self.noise)\n",
        "      \n",
        "        self.time_step += 1\n",
        "        return action_prob\n",
        "  \n",
        "    def store(self, initial_state, action, reward, final_state, terminal):\n",
        "        self.memory.push(initial_state, action, reward, final_state, terminal)\n",
        "    \n",
        "    def learn(self):\n",
        "        if self.memory.counter < self.batch_size:\n",
        "            return\n",
        "        \n",
        "        initial_states, actions, rewards, final_states, terminals, weights, indexes = self.memory.pop(self.batch_size, self.memory_beta)\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            target_actions = self.target_actor(final_states) + tf.clip_by_value(np.random.normal(scale=0.2), -0.5, 0.5)\n",
        "\n",
        "            q1_ = tf.squeeze(self.target_critic_1(final_states, target_actions), 1)\n",
        "            q2_ = tf.squeeze(self.target_critic_2(final_states, target_actions), 1)\n",
        "\n",
        "            q1 = tf.squeeze(self.critic_1(initial_states, actions), 1)\n",
        "            q2 = tf.squeeze(self.critic_2(initial_states, actions), 1)\n",
        "\n",
        "            critic_value = tf.math.minimum(q1_, q2_)\n",
        "\n",
        "            td_target = rewards + self.discount_factor * critic_value * (1 - terminals)\n",
        "            td_error = td_target - tf.math.minimum(q1, q2)\n",
        "            critic_1_loss = keras.losses.MSE(td_target * tf.math.sqrt(weights), q1) \n",
        "            critic_2_loss = keras.losses.MSE(td_target * tf.math.sqrt(weights), q2)\n",
        "        \n",
        "        self.memory.update_priorities(indexes, tf.math.abs(td_error))\n",
        "        self.update_network(self.critic_1, tape, critic_1_loss)\n",
        "        self.update_network(self.critic_2, tape, critic_2_loss)\n",
        "\n",
        "        self.learn_step_counter += 1\n",
        "\n",
        "        if self.learn_step_counter % self.delay_coeff_actor != 0:\n",
        "            return\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            new_actions = self.actor(initial_states)\n",
        "            critic_1_value = self.critic_1(initial_states, new_actions)\n",
        "            actor_loss = -tf.math.reduce_mean(critic_1_value * weights) \n",
        "        self.update_network(self.actor, tape, actor_loss)\n",
        "\n",
        "        self.update_target()\n",
        "\n",
        "    def update_network(self, network, tape, loss):\n",
        "        network_gradient = tape.gradient(loss, network.trainable_variables)\n",
        "        network.optimizer.apply_gradients(zip(network_gradient, network.trainable_variables))\n",
        "\n",
        "    def save(self):\n",
        "        print('Saing models and parameters...')\n",
        "        pickle.dump([self.memory, self.learn_step_counter, self.time_step], open(os.path.join(self.checkpoint_dir, '_params_td3'), \"wb\"))\n",
        "        self.actor.save_weights(self.actor.checkpoint_file)\n",
        "        self.critic_1.save_weights(self.critic_1.checkpoint_file)\n",
        "        self.critic_2.save_weights(self.critic_2.checkpoint_file)\n",
        "        self.target_actor.save_weights(self.target_actor.checkpoint_file)\n",
        "        self.target_critic_1.save_weights(self.target_critic_1.checkpoint_file)\n",
        "        self.target_critic_2.save_weights(self.target_critic_2.checkpoint_file)\n",
        "\n",
        "    def load(self):\n",
        "        print('Loading models and parameters...')\n",
        "        self.memory, self.learn_step_counter, self.time_step = pickle.load(open(os.path.join(self.checkpoint_dir, '_params_td3'), \"rb\"))\n",
        "        self.actor.load_weights(self.actor.checkpoint_file)\n",
        "        self.critic_1.load_weights(self.critic_1.checkpoint_file)\n",
        "        self.critic_2.load_weights(self.critic_2.checkpoint_file)\n",
        "        self.target_actor.load_weights(self.target_actor.checkpoint_file)\n",
        "        self.target_critic_1.load_weights(self.target_critic_1.checkpoint_file)\n",
        "        self.target_critic_2.load_weights(self.target_critic_2.checkpoint_file)"
      ],
      "metadata": {
        "id": "xrc309SPtgqk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Breakout-v0')"
      ],
      "metadata": {
        "id": "08qlAxdloMRW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_dic = {0: \n",
        "     {'name': 'Conv2D',\n",
        "      'params': {\n",
        "          'filters': 32, \n",
        "          'kernel_size': (8,8),\n",
        "          'strides': (4,4),\n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     1: \n",
        "     {'name': 'Conv2D',\n",
        "      'params': {\n",
        "          'filters': 64, \n",
        "          'kernel_size': (4,4),\n",
        "          'strides': (2,2),\n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     2: \n",
        "     {'name': 'Conv2D',\n",
        "      'params': {\n",
        "          'filters': 64, \n",
        "          'kernel_size': (3,3),\n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     3: \n",
        "     {'name': 'Flatten',\n",
        "      'params': {}\n",
        "      },\n",
        "     4: \n",
        "     {'name': 'Dense',\n",
        "      'params': {\n",
        "          'units': 512, \n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     5: \n",
        "     {'name': 'Dense',\n",
        "      'params': {\n",
        "          'units': 256, \n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     6: \n",
        "     {'name': 'Dense',\n",
        "      'params': {\n",
        "          'units': env.action_space.n, \n",
        "          'activation': 'linear'\n",
        "      }},\n",
        "      }"
      ],
      "metadata": {
        "id": "M6RTk7GOq6DL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crit_dic = {0: \n",
        "     {'name': 'Conv2D',\n",
        "      'params': {\n",
        "          'filters': 32, \n",
        "          'kernel_size': (8,8),\n",
        "          'strides': (4,4),\n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     1: \n",
        "     {'name': 'Conv2D',\n",
        "      'params': {\n",
        "          'filters': 64, \n",
        "          'kernel_size': (4,4),\n",
        "          'strides': (2,2),\n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     2: \n",
        "     {'name': 'Conv2D',\n",
        "      'params': {\n",
        "          'filters': 64, \n",
        "          'kernel_size': (3,3),\n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     3: \n",
        "     {'name': 'Flatten',\n",
        "      'params': {}\n",
        "      },\n",
        "     4: \n",
        "     {'name': 'Dense',\n",
        "      'params': {\n",
        "          'units': 512, \n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     5: \n",
        "     {'name': 'Dense',\n",
        "      'params': {\n",
        "          'units': 256, \n",
        "          'activation': 'relu'\n",
        "      }},\n",
        "     6: \n",
        "     {'name': 'Dense',\n",
        "      'params': {\n",
        "          'units': 1, \n",
        "          'activation': 'linear'\n",
        "      }},\n",
        "      }"
      ],
      "metadata": {
        "id": "IpcbArGxtv-X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = TD3Agent(env, 0.001, 0.001, keras.losses.MSE, keras.losses.MSE, 0.005, 0.99, 2, 0.1, 1000, 1024, 0.7, 0.4, 32, act_dic, crit_dic)"
      ],
      "metadata": {
        "id": "H05qOjkApzLE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhOztCFZMR1K",
        "outputId": "b87751cd-be8d-4f55-e4db-59b84ec94ec7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "408"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_games = 3\n",
        "filename = 'plots/' + 'walker_' + str(n_games) + '_games.png'\n",
        "\n",
        "best_score = env.reward_range[0]\n",
        "score_history = []\n",
        "frames = []\n",
        "\n",
        "for i in range(n_games):\n",
        "    actual_state = env.reset()\n",
        "    env.step(1)\n",
        "    terminal = False\n",
        "    score = 0\n",
        "    game_frame = []\n",
        "    while not terminal:\n",
        "        game_frame.append(env.render(mode = 'rgb_array'))\n",
        "        actions_prob = agent.act(actual_state)\n",
        "        next_state, reward, terminal, info = env.step([np.argmax(i) for i in actions_prob])\n",
        "        agent.store(actual_state, actions_prob, reward, next_state, terminal)\n",
        "        agent.learn()\n",
        "        score += reward\n",
        "        actual_state = next_state\n",
        "    score_history.append(score)\n",
        "    avg_score = np.mean(score_history[-100:])\n",
        "    frames.append(game_frame)\n",
        "\n",
        "    if avg_score > best_score:\n",
        "        best_score = avg_score\n",
        "        #agent.save()\n",
        "\n",
        "    print('episode ', i, 'score %.1f' % score, 'average score %.1f' % avg_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGrFrTx5oGq5",
        "outputId": "14539932-ed00-40b3-9ffe-02c93e67d0b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode  0 score 0.0 average score 0.0\n",
            "episode  1 score 4.0 average score 2.0\n",
            "episode  2 score 1.0 average score 1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "epwrc2JJv3uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = [[Image.fromarray(i) for i in j] for j in frames]"
      ],
      "metadata": {
        "id": "HJOEVlo4tj4V"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, game in enumerate(images):\n",
        "  game[0].save('out'+str(i)+'.gif', save_all=True, append_images=game[1:])"
      ],
      "metadata": {
        "id": "E0YUUyMWpUPI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curve(x, scores, figure_file):\n",
        "    running_avg = np.zeros(len(scores))\n",
        "    for i in range(len(running_avg)):\n",
        "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
        "    plt.plot(x, running_avg)\n",
        "    plt.title('Running average of previous 100 scores')\n",
        "    plt.savefig(figure_file)"
      ],
      "metadata": {
        "id": "NVTaHiBlzyUy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [i+1 for i in range(n_games)]\n",
        "plot_learning_curve(x, score_history, filename)"
      ],
      "metadata": {
        "id": "ELR_8UfxzebF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "42c8af28-06cd-40b8-f268-ea86529b7164"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-28c326654726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-206edec97724>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(x, scores, figure_file)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running average of previous 100 scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[1;32m    537\u001b[0m                                metadata={**default_metadata, **metadata})\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plots/walker_3_games.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}