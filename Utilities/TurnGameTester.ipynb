{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "TurnGameTester.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import"
   ],
   "metadata": {
    "id": "i4btHclS3JI4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\menta\\Desktop\\PythonProjects\\Advanced_Deep_Learning_Models_and_Methods-Menta-Nisti\\Utilities\\Santorini.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ACTION_SPACE = np.array([[2, 8, 8], [2, 3, 3, 3, 3]]) #Deprecato\n"
     ]
    }
   ],
   "source": [
    "# IMPORT FOR BASIC UTILITIES\n",
    "\n",
    "import sys\n",
    "import io\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import gym\n",
    "from Agents.DDDQN.DDDQNAgent import DDDQNAgent\n",
    "#from Agents.TD3.TD3Agent import TD3Agent\n",
    "from Utilities.TicTacToe import TicTacToeEnv\n",
    "#from Utilities.ConnectFour import ConnectFourEnv\n",
    "#from Utilities.Santorini import SantoriniEnv\n",
    "from Utilities.Wrappers import OpponentWrapper\n",
    "from Utilities.TrainWizard import TurnGameTrainWizard\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST CONFIGURATION\n",
    "\n",
    "algorithm = 'DDDQN'\n",
    "environment = 'TicTacToe'\n",
    "representation = 'Tabular'\n",
    "opponent = 'Random'\n",
    "agent_turn = 'First'\n",
    "\n",
    "config_name = algorithm + '_' + environment + '_' + representation + '_' + opponent + '_' + agent_turn\n",
    "data_path = '..\\\\Results\\\\' + config_name + '\\\\'\n",
    "gif_path = data_path + 'GIFs\\\\'\n",
    "network_path = data_path + 'NetworkParameters\\\\'\n",
    "! mkdir $data_path\n",
    "! mkdir $gif_path\n",
    "! mkdir $network_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GAME PARAMETERS AND NETWORK STRUCTURE\n",
    "\n",
    "env = OpponentWrapper(TicTacToeEnv(representation, agent_turn=='First'), 'Random')\n",
    "\n",
    "network_dict_base = {0: \n",
    "     {'name': 'Dense',\n",
    "      'params': {\n",
    "          'units': 64, \n",
    "          'activation': 'relu',\n",
    "          'kernel_initializer': tf.keras.initializers.HeNormal()\n",
    "      }},\n",
    "     1: \n",
    "     {'name': 'Dense',\n",
    "      'params': {\n",
    "          'units': 32, \n",
    "          'activation': 'relu',\n",
    "          'kernel_initializer': tf.keras.initializers.HeNormal()\n",
    "      }}}\n",
    "network_dict_advantage = {2: \n",
    "     {'name': 'Flatten',\n",
    "      'params': {}\n",
    "      },\n",
    "      3: \n",
    "      {'name': 'Dense',\n",
    "       'params': {\n",
    "          'units': env.action_space.n, \n",
    "          'activation': 'relu',\n",
    "          'kernel_initializer': tf.keras.initializers.HeNormal()\n",
    "      }}}\n",
    "network_dict_value = {4: \n",
    "     {'name': 'Flatten',\n",
    "      'params': {}\n",
    "      },\n",
    "      5: \n",
    "      {'name': 'Dense',\n",
    "      'params': {\n",
    "          'units': 1, \n",
    "          'activation': 'relu',\n",
    "          'kernel_initializer': tf.keras.initializers.HeNormal()\n",
    "      }}}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AGENT\n",
    "\n",
    "agent = DDDQNAgent(environment=env,\n",
    "                   q_net_dict=[network_dict_base, network_dict_advantage, network_dict_value],\n",
    "                   q_target_net_dict=[network_dict_base, network_dict_advantage, network_dict_value], \n",
    "                   double_q=True, \n",
    "                   dueling_q=True, \n",
    "                   q_net_update=4,\n",
    "                   q_target_net_update=10000, \n",
    "                   discount_factor=0.99, \n",
    "                   q_net_optimizer=keras.optimizers.Adam, \n",
    "                   q_target_net_optimizer=keras.optimizers.Adam, \n",
    "                   q_net_learning_rate=1e-5,\n",
    "                   q_target_net_learning_rate=1e-5, \n",
    "                   q_net_loss=keras.losses.Huber(), \n",
    "                   q_target_net_loss=keras.losses.Huber(), \n",
    "                   num_episodes=100000,\n",
    "                   memory_size=8192, \n",
    "                   memory_alpha=0.7, \n",
    "                   memory_beta=0.4, \n",
    "                   max_epsilon=1.0, \n",
    "                   min_epsilon=0.001, \n",
    "                   epsilon_A=0.35, \n",
    "                   epsilon_B=0.25, \n",
    "                   epsilon_C=0.1,\n",
    "                   batch_size=32, \n",
    "                   checkpoint_dir=network_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WIZARD\n",
    "\n",
    "wizard = TurnGameTrainWizard(environment=env,\n",
    "                     agent=agent,\n",
    "                     objective_score=1,\n",
    "                     running_average_length=100,\n",
    "                     evaluation_steps=1000,\n",
    "                     evaluation_games=100,\n",
    "                     agent_turn=True,\n",
    "                     agent_turn_test=True,\n",
    "                     opponent='Random',\n",
    "                     path=data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wizard.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16,9)})\n",
    "data = np.array([(key, value[0][i][0], value[0][i][1]) for key, value in wizard.eval_reward_history.items() for i in range(len(value[0]))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.lineplot(data[:,0], data[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.lineplot(data[:,0], data[:,2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}